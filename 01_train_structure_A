# -*- coding: utf-8 -*-
"""
[Step 1] Train DeepONet on Structure A
Feature: Asymmetric Loss, DI in Branch Net
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import os
from scipy.stats import kurtosis
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# --- ì„¤ì • ---
DATA_PATH = r"E:\Benchmark Code\benchmarktu1402-master\f_accerlerations\ds1"
SAVE_MODEL_PATH = "deeponet_phase2_structure_A.pth"
SELECTED_NODE_INDICES = [3, 21, 39, 57, 63, 81, 99, 117]
WINDOW_SIZE = 128
TRAIN_POINTS = 128000
FS = 1000.0
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- ëª¨ë¸ ì •ì˜ ---
class FourierFeature(nn.Module):
    def __init__(self, input_dim, mapping_size=256, scale=15):
        super().__init__()
        self.register_buffer('B', torch.randn(input_dim, mapping_size) * scale)
    def forward(self, x):
        projected = 2 * np.pi * (x @ self.B)
        return torch.cat([torch.sin(projected), torch.cos(projected)], dim=-1)

class DeepONetPhase2(nn.Module):
    def __init__(self, branch_dim, trunk_dim, hidden_dim=256, output_dim=256):
        super().__init__()
        self.activation = nn.SiLU()
        self.branch = nn.Sequential(
            nn.Linear(branch_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, output_dim),
        )
        self.fourier_dim = 256
        self.fourier = FourierFeature(trunk_dim, mapping_size=self.fourier_dim, scale=15.0)
        self.trunk = nn.Sequential(
            nn.Linear(self.fourier_dim * 2, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, output_dim),
        )
        self.bias = nn.Parameter(torch.zeros(1))
    def forward(self, u, y):
        B = self.branch(u)
        y_embedded = self.fourier(y)
        T = self.trunk(y_embedded)
        B_expanded = B.unsqueeze(1)
        return torch.sum(B_expanded * T, dim=-1) + self.bias

# --- ë¹„ëŒ€ì¹­ Loss ---
def peak_weighted_mse_loss(pred, target):
    base_loss = (pred - target) ** 2
    weight = torch.where(target > 0, 3.0, 1.0) # ì–‘ìˆ˜ í”¼í¬ì— 3ë°° ê°€ì¤‘ì¹˜
    return torch.mean(weight * base_loss)

# --- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ (ìƒëµ ì—†ì´ êµ¬í˜„ í•„ìš” ì‹œ ì´ì „ ëŒ€í™” ì°¸ì¡°) ---
# (ì´ ë¶€ë¶„ì€ Structure A ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ U, Y, Gë¥¼ ë§Œë“œëŠ” create_dataset_phase2 í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.)
# ... (create_dataset_phase2 ë¡œì§ êµ¬í˜„) ...

def main():
    print(f"ğŸš€ Training Start on {device}")
    # ë°ì´í„°ì…‹ ìƒì„± (ë©”ëª¨ë¦¬ ë¬¸ì œ ì‹œ ë°°ì¹˜ ì²˜ë¦¬ í•„ìš”)
    # (U_train, Y_train, G_train) ë¡œë“œ ë¡œì§
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = DeepONetPhase2(branch_dim=1025, trunk_dim=2).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=0.001)
    
    # í•™ìŠµ ë£¨í”„ (AdamW -> L-BFGS)
    # ...
    
    torch.save(model.state_dict(), SAVE_MODEL_PATH)
    print(f"Model saved to {SAVE_MODEL_PATH}")

if __name__ == "__main__":
    pass # ì‹¤ì œ ì‹¤í–‰ ì‹œì—ëŠ” main() í˜¸ì¶œ
